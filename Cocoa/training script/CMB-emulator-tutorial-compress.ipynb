{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed1692fa",
   "metadata": {},
   "source": [
    "**CMB emulator training tutorial-compressed way**\\\n",
    "This tutorial goes through how to train an emulator for CMB power spectrum. This tutorial, different from the other tutorial for training, compress the codes of defining models and training process in a package called **emulator**. This one is intended to be more user-friendly, while the other one is intended more for people to understand the process of developing the code and can modify codes according to their own need. We use CMB TT power spectrum as the example here, and same strategies will apply to EE and TE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1b3a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import camb\n",
    "import scipy.linalg\n",
    "from camb import model, initialpower\n",
    "from camb.dark_energy import DarkEnergyPPF, DarkEnergyFluid\n",
    "import emulator\n",
    "from emulator import Supact, Affine, Better_Attention, Better_Transformer, ResBlock, ResMLP, TRF, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34aa5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SET UP CMB POWER SPECTRA RANGE #####\n",
    "\n",
    "camb_ell_min          = 2\n",
    "camb_ell_max          = 5000\n",
    "camb_ell_range        = camb_ell_max - camb_ell_min\n",
    "\n",
    "##### PICK DEVICE ON WHICH THE MODEL WILL BE TRAINED ON. WE RECOMMEND USING GPU FOR TRAINING #####\n",
    "device                = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#CUDA for GPU\n",
    "#CPU for CPU\n",
    "#GPU is generally recommended for higher speed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c936dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### LOAD UP MEAN AND STD FOR INPUT AND OUTPUT #####\n",
    "extrainfo=np.load(\"extra/extrainfo_plk_tt_first_T256.npy\",allow_pickle=True)\n",
    "X_mean=torch.Tensor(extrainfo.item()['X_mean'])#.to(device)\n",
    "X_std=torch.Tensor(extrainfo.item()['X_std'])#.to(device)\n",
    "Y_mean=torch.Tensor(extrainfo.item()['Y_mean']).to(device)\n",
    "Y_std=torch.Tensor(extrainfo.item()['Y_std']).to(device)\n",
    "\n",
    "##### LOAD UP COV MAT #####\n",
    "covinv=np.load('/home/grads/data/yijie/mltrial/extra/cosvarinvTT.npy',allow_pickle=True)[:camb_ell_range,:camb_ell_range]\n",
    "covinv=torch.Tensor(covinv).to(device) #This is inverse of the Covariance Matrix\n",
    "\n",
    "\n",
    "#load in data\n",
    "train_samples=np.load('parametersamples/cos_pkc_T256_firsttest.npy',allow_pickle=True)\n",
    "\n",
    "validation_samples=np.load('parametersamples/cos_pkc_T128.npy',allow_pickle=True)[:10000]\n",
    "\n",
    "train_data_vectors=np.load('datavectors/Planck256/cos_pkc_T256_firsttest_TT.npy',allow_pickle=True,mmap_mode='r+')\n",
    "\n",
    "validation_data_vectors=np.load('datavectors/Planck128/cos_pkc_T128_TT_acc.npy',allow_pickle=True)[:10000,:4998]\n",
    "train_samples=torch.Tensor(train_samples)\n",
    "train_data_vectors=torch.Tensor(train_data_vectors)\n",
    "validation_samples=torch.Tensor(validation_samples)\n",
    "validation_data_vectors=torch.Tensor(validation_data_vectors)\n",
    "#specifying input and output dimension of our model\n",
    "input_size=len(train_samples[0])\n",
    "out_size=len(train_data_vectors[0])\n",
    "\n",
    "\n",
    "\n",
    "#normalizing samples and to mean 0, std 1\n",
    "\n",
    "X_train=(train_samples-X_mean)/X_std\n",
    "X_train[:,6:]=0 # we didn't vary the last 3 parameters: mnu, w, and wa in this test, so setting them to 0 automatically after normalization\n",
    "\n",
    "X_validation=(validation_samples-X_mean)/X_std\n",
    "X_validation[:,6:]=0 # we didn't vary the last 3 parameters: mnu, w, and wa in this test, so setting them to 0 automatically after normalization\n",
    "\n",
    "X_train=X_train.to(torch.float32)\n",
    "X_validation=X_validation.to(torch.float32)\n",
    "\n",
    "X_mean=X_mean.to(device)\n",
    "X_std=X_std.to(device)\n",
    "\n",
    "#load the data to batches. Do not send those to device yet to save space\n",
    "batch_size = 512\n",
    "\n",
    "trainset    = TensorDataset(X_train, train_data_vectors)\n",
    "validset    = TensorDataset(X_validation,validation_data_vectors)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=1)\n",
    "validloader = DataLoader(validset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e73ef2f",
   "metadata": {},
   "source": [
    "Here we start defining Machine learning Modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c88b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "intdim = 4    # internal dimension of the ResMLP blocks\n",
    "int_trf = 5120# internal dimension of the Transformer block\n",
    "nc=32         # number of channels we pick\n",
    "\n",
    "#Set up the model and optimizer\n",
    "model = TRF(input_dim=input_size,output_dim=out_size,int_dim=intdim, int_trf=int_trf,N_channels=nc)\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),weight_decay=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd160db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the learning rate scheduler\n",
    "reduce_lr = True#reducing learning rate on plateau\n",
    "if reduce_lr==True:\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',factor=0.5,patience=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c476b56",
   "metadata": {},
   "source": [
    "**TRAINING PROCESS**\\\n",
    "Here we use the loss function of $L=\\sqrt{1+2\\chi^2}$. The users should test out\n",
    "their own best Loss functions and modify the code correspondingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2ce5b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduce LR on plateu:  True\n",
      "epoch 0, loss=16025.001953125, validation loss=5010.69677734375, lr=0.001, wd=0)\n",
      "Saved to./trainedemu5000plktrf/chiTTAstautestc32.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "n_epoch = 1 #just for demo, in reality you need around 500 to 700 or more epochs\n",
    "PATH = \"./trainedemu5000plktrf/chiTTAstautestc\"+str(nc)\n",
    "train(model, scheduler, optimizer, trainloader, validloader, n_epoch, covinv, device,X_mean, X_std, Y_mean, Y_std, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807582b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
